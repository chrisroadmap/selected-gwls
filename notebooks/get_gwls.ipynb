{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = glob.glob('../data/anomalies/*')\n",
    "models = []\n",
    "for model_path in model_paths:\n",
    "    models.append(model_path.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssps = ['ssp585', 'ssp370', 'ssp245', 'ssp126']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scen_runs = {}\n",
    "for model_path in model_paths:\n",
    "    model = model_path.split('/')[-1]\n",
    "    model_scen_runs[model] = {}\n",
    "    for ssp in ssps:\n",
    "        file_paths = glob.glob(f'{model_path}/{ssp}/*')\n",
    "        model_scen_runs[model][ssp] = []\n",
    "        for file_path in file_paths:\n",
    "            file_name = file_path.split('/')[-1]\n",
    "            run = file_name.split('_')[2]\n",
    "            model_scen_runs[model][ssp].append(run)\n",
    "    file_paths = glob.glob(f'{model_path}/historical/*')\n",
    "    model_scen_runs[model]['historical'] = []\n",
    "    for file_path in file_paths:\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        run = file_name.split('_')[2]\n",
    "        model_scen_runs[model]['historical'].append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_scen_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/anomalies'\n",
    "\n",
    "output_means = {}\n",
    "\n",
    "for model in model_scen_runs:\n",
    "    output_means[model] = {}\n",
    "    for ssp in ssps:\n",
    "        hist_and_ssp_runs = [run for run in model_scen_runs[model][ssp] if run in model_scen_runs[model]['historical']]\n",
    "        # discard if the run does not go until at least 2099\n",
    "        too_short = []\n",
    "        shortest_run = 10000\n",
    "        for irun, run in enumerate(hist_and_ssp_runs):\n",
    "            ssp_df = pd.read_csv(glob.glob(f'{base_path}/{model}/{ssp}/*_{run}_*.csv')[0], index_col='year')\n",
    "            post_2014_years = len(ssp_df)\n",
    "            if post_2014_years < 85:\n",
    "                too_short.append(run)\n",
    "            else:\n",
    "                shortest_run = min(shortest_run, post_2014_years+165)\n",
    "        retained_runs = [run for run in hist_and_ssp_runs if run not in too_short]\n",
    "        n_runs = len(retained_runs)\n",
    "        data = np.ones((shortest_run, n_runs)) * np.nan\n",
    "        for irun, run in enumerate(retained_runs):\n",
    "            ssp_df = pd.read_csv(glob.glob(f'{base_path}/{model}/{ssp}/*_{run}_*.csv')[0], index_col='year')\n",
    "            hist_df = pd.read_csv(glob.glob(f'{base_path}/{model}/historical/*_{run}_*.csv')[0], index_col='year')\n",
    "            full_df = pd.concat((hist_df, ssp_df))\n",
    "            data[:, irun] = full_df['tas'].values[:shortest_run]\n",
    "        output_means[model][ssp] = pd.DataFrame(data.mean(axis=1), index=np.arange(1850, 1850+shortest_run), columns=['tas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwls = [1.5, 2.0, 3.0, 4.0]\n",
    "crossing_years = []\n",
    "for model in models:\n",
    "    for ssp in ssps:\n",
    "        rolling_df = output_means[model][ssp].rolling(window=19, center=True).mean()['tas']\n",
    "        row = [model, ssp]\n",
    "        for gwl in gwls:\n",
    "            try:\n",
    "                row.append(rolling_df[rolling_df.gt(gwl)].index[0])\n",
    "            except IndexError:\n",
    "                row.append(np.nan)\n",
    "        crossing_years.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(crossing_years, columns=['model', 'scenario', 'GWL1.5', 'GWL2.0', 'GWL3.0', 'GWL4.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../output', exist_ok=True)\n",
    "df_out.to_csv('../output/gwl.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
